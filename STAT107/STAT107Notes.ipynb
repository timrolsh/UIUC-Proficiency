{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Discovery (STAT 107) General Notes\n",
    "\n",
    "## Reflection After Proficiency Exam\n",
    "\n",
    "This class is very heavy statistics focused and not as much machine learning and computer science focused. Definitely be familiar with the core concepts of AP Statistics (distributions, proportions and means significance tests and confidence intervals, probability, experimental design, and linear regression). Be highly familiar with the scipy functions for normal distributions (norm(), norm.cdf(), norm.pmf/pdf(), norm.ppf()). The actual proficiency exam is very similar. Definitely watch all of the videos and review the stats concepts and use this link for their proficiency page: [https://discovery.cs.illinois.edu/proficiency-exam/](https://discovery.cs.illinois.edu/proficiency-exam/)\n",
    "\n",
    "## Data Science General Definition\n",
    "\n",
    "**Computation**: Using computer based tools to explore data\n",
    "\n",
    "**Inference**: Use statistical methods (like linear regression) to understand trends/relations in data\n",
    "\n",
    "**Business Intelligence**: Gaining knowledge and making conclusions from exploration of data\n",
    "\n",
    "**Data Science**: Intersection between these three fields all together\n",
    "    * My definition: Using computer based tools and combining them with statistical methods to understand trends and relations in complex data, recognize complex patterns through the enhancement of computing, and therefore be able to gain knowledge and make sophisticated conclusions from this analysis\n",
    "**Sample Space**: The set of all possible outcomes a certain event happening\n",
    "\n",
    "* For instance the sample set for rolling 2 die together would have a sample space with $6^2=36$ entries in it of every possible combination\n",
    "\n",
    "## Types of Data\n",
    "\n",
    "**Structured Data**: Data that is organized (representable in tabular data/spreadsheet) and labeled\n",
    "    * Bulk of data in this class will be structured\n",
    "\n",
    "**Unstructured Data**: Anything that doesn't meet requirements for structured data\n",
    "    *Image: An image file is organized and encoded into a format but isn't labeled with different areas of it\n",
    "    * Text, Newspapers, etc. none of these are both labeled and organized\n",
    "\n",
    "## Structured Data Interactions\n",
    "\n",
    "* Stored in CSVs in files for computing contexts often (frameworks can load csvs)\n",
    "* Loaded into Pandas dataframes\n",
    "\n",
    "## Experimental Design, Blocking Review\n",
    "\n",
    "* Experiments perform some kind of treatment on a subject and determine if the treatment has a meaningful result\n",
    "  * In experiments researcher has control over who gets treatment and who doesn't they split it accordingly: control group doesn't get treatment, another group does get treatment\n",
    "  * Observational study: Researcher has no control over splitting or treatment groups and just observes and then performs analysis on the data of a scenario\n",
    "**Components of an experiment**: Randomization/Random Assignment, Control Group, Double Blind (neither subject nor evaluator know which group they are in)\n",
    "\n",
    "**Ideal Experiment**: Randomized double blind experiment that is blocked into different groups if necessary\n",
    "\n",
    "**Blocking**: Step before splitting into treatment and control group: For instance you can do 2 blocks A students and B students before you split each block into treatment and control\n",
    "\n",
    "## Observational Studies Review\n",
    "\n",
    "* Researcher observes a scenario and does not provide any kind of treatment or have control or RA or blocking or anything like that\n",
    "* You can show correlation from observational studies but you cannot make conclusions or establish causation from them\n",
    "* **Casual Link**: Actual connection between treatment group, treatment, and response\n",
    "* **Confounder/Confounding Variable**: Something that affects the treatment group in a situation and can confound/interfere with the true effects fo the treatment being applied and make researcher believe that treatment is affecting the group when in reality its a confounding variable\n",
    "* **Stratification**: Splitting into similar homogeneous groups (women and men group would make sense to do before doing height and weight analysis for example)\n",
    "  * Like blocking but for observational studies\n",
    "  * Helps remove confounding variables and isolate only the effects of the treatment\n",
    "  * When you stratify you observe first then stratify, when you block you block first then perform treatment\n",
    "* **Simpson's Paradox**: When treatment and control groups are cumulatively compared without stratification and a pattern appears, but when they are stratified into homogeneous groups these patterns disappear\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "* Performing investigations on data to get familiar with it, discover patterns and outliers, check assumptions and make inferences\n",
    "* First thing you do when you get a raw dataset that might not be very\n",
    "* Missing values: Can represent them as a constant (0), find replacements like averages or randomly selected values, use models\n",
    "\n",
    "## Histograms Review\n",
    "\n",
    "* They are bar graphs for one var stats, categorical variable you get from making ranges for the quantitative variable and everything in that range goes into that category, categories are then added up and displayed\n",
    "* Useful for seeing distribution of data\n",
    "* **Frequency Histogram**: Histogram with raw counts/frequencies for each range displayed\n",
    "* **Density Histogram**: Histogram with relative frequencies to the entire dataset, sum of all bar frequencies will add up to 1\n",
    "\n",
    "## Central Limit Theorem (CLT) Review\n",
    "\n",
    "* Sampling distribution of sample means will always be normally distributed as long as ${n}\\ge{30}$\n",
    "* $\\displaystyle\\text{Error}{\\left({n}\\right)}=\\frac{1}{{e}}\\text{Error}{\\left({n}\\times{e}^{2}\\right)}$\n",
    "  * To reduce the error of sample size `n` by a factor `e` you need to multiply your existing sample size by $e^2$\n",
    "\n",
    "## Python Randomness\n",
    "\n",
    "* `random.randint(lower: int, upper: int)` is inclusive of boundaries\n",
    "* `random.choice(items: list)` will pick one item out from the list\n",
    "\n",
    "## Normal Distribution Review\n",
    "\n",
    "**Standard Normal Distribution**: $\\displaystyle\\mu={0},\\sigma={0},\\text{median}={0}$, total area under the curve is `1`\n",
    "\n",
    "* $\\displaystyle{z}=\\frac{{\\text{value}-\\mu}}{\\sigma}$\n",
    "* `norm.cdf(z_score: float)`: normNormal CDF Function: Returns area under the curve left the z score\n",
    "* `norm.ppf(area: float)`: Point probability function/inverse normal cdf function: Returns z score at which area to the left of the z score under the distribution is the provided number\n",
    "* `norm(mean: float, standard_deviation: float)`: creates a normal distribution with a custom mean and standard deviation, all the same method calls will work you just won't have to do use z score on it\n",
    "\n",
    "## Law of Large Numbers\n",
    "\n",
    "* The more times you run an experiment, the more likely your results will take shape of the expected values\n",
    "* If you toss coins you're expected to on average roll a value of $\\displaystyle\\frac{{{1}+{2}+{3}+{4}+{5}+{6}}}{{6}}={3.5}$, the more trials you run, the closer $\\mu$ of your rolls will be to $3.5$\n",
    "* **Expected value**: Mean of all possible outcomes of an event, you can \"expect\" something similar to this value when you perform trials of the event\n",
    "  * You will trend more towards this expected value as you take the average of more and more trials of the event you perform\n",
    "* **Cumulative Sum**: Sum of everything up to and including this row, usage: `df[\"result\"].cumsum()`\n",
    "* **Cumulative Average**: Average of everything up and including this row, usage: `df[\"result\"].cumsum() / (df.index + 1)`\n",
    "\n",
    "## Probability Review\n",
    "\n",
    "* Definition of probability: $\\displaystyle{P}{\\left(\\text{Event}\\right)}=\\frac{\\text{Number of outcomes of event}}{\\text{Total outcomes in sample space}}$\n",
    "  * Always a number in the range: $\\displaystyle{\\left[{0},{1}\\right]}$\n",
    "* $\\displaystyle{P}{\\left({A}{|}{B}\\right)}$: Probability of event A occurring, given that event B has already occurred\n",
    "  * Multiplication rule for intersections/and: $\\displaystyle{P}{\\left({A}\\cap{B}\\right)}={P}{\\left({A}{|}{B}\\right)}\\times{P}{\\left({B}\\right)}$\n",
    "* $\\displaystyle{P}{\\left({A}^{o}\\right)}={1}-{P}{\\left({A}\\right)}$: Complement to probability, probability of that event not happening\n",
    "* **Independence**: When probability of one event is not influenced by another event happening\n",
    "  * Drawing cards from a deck with replacement is **independent**, without replacement is **dependent**\n",
    "  * $\\displaystyle{P}{\\left({A}{|}{B}\\right)}={P}{\\left({A}{|}{B}^{o}\\right)}={P}{\\left({A}\\right)}$\n",
    "* Addition rule for unions/or: $\\displaystyle{P}{\\left({A}\\cup{B}\\right)}={P}{\\left({A}\\right)}+{P}{\\left({B}\\right)}-{P}{\\left({A}\\cap{B}\\right)}$: Unions from or\n",
    "  * Mutually exclusive case: $\\displaystyle{P}{\\left({A}\\cap{B}\\right)}={0}$\n",
    "* Bayes' Theorem: $\\displaystyle{P}{\\left({A}{|}{B}\\right)}={P}{\\left({B}{|}{A}\\right)}\\times\\frac{{{P}{\\left({A}\\right)}}}{{{P}{\\left({B}\\right)}}}$\n",
    "\n",
    "## Random Variables\n",
    "\n",
    "* **Discrete Random Variable**: Variable that has finite amount of possible values, example: all integers in range $\\displaystyle{\\left[{2},{7}\\right]}$\n",
    "* **Continuous Random Variable**: Variable that has infinite amount of possible values, example: all floats in range $\\displaystyle{\\left[{0},{1}\\right]}$\n",
    "* **Binomial Distribution**: Distribution with certain number of trials and certain probability of each trial occuring\n",
    "  * `binomCDF()` and `binomPDF()` come from here\n",
    "  * Expected number of successes: $np$\n",
    "  * Standard error for expected number: $\\displaystyle\\sqrt{{{n}{p}{\\left({1}-{p}\\right)}}}$\n",
    "  * `binom(n: int, p: float).cdf(successful_outcomes: float)`: binomCDF function for `successful_outcomes` and lower\n",
    "  * `binom(n: int, p: float).ppf(fraction_covered: float)`: invNorm or probability point function, returns successful outcomes at percentile\n",
    "  * `binom(n: int, p: float).pmf(succesful_outcome: int)`: binomPDF function for specific number of successful attempts\n",
    "    * you can use `pdf` but thats for continuous scenarios most of the contexts are going to be discrete so use pmf\n",
    "    * Continuous case: You have sun screen expected to work on 6 hours with 1 hr standard deviation normally distributed, to find how likely its going to last around 4 hours you do `norm().pdf((value - mean) / standard_deviation)`\n",
    "  * `binom(n: int, p: float).rvs(num_trials: int)`: Returns an array of length num_trials with results randomly selected according to the defined distribution, for instance a value of `pmf(value) = 0.3` has an 0.3 chance of appearing in each entry in the array\n",
    "* **Bernoulli Distribution**: Like a binomial distribution where `n = 1`, for instance drawing 1 card from a deck, etc. You define it in scipy: `bernoulli()`\n",
    "* On any scipy distribution you can do `mean()` for mean, `std()` for standard deviation\n",
    "\n",
    "## Confidence Intervals and Hypothesis Tests Review\n",
    "\n",
    "* For means here they just use z-score and normal distribution instead of t and t distribution\n",
    "* $\\displaystyle{x}\\pm\\text{norm.ppf}{\\left(\\frac{{{1}+\\text{confidence level}}}{{2}}\\right)}\\frac{{s}_{{x}}}{\\sqrt{{{n}}}}$\n",
    "  * Confidence level here will usually also be `95%` by default\n",
    "  * $s_x$: the standard deviation for the sample\n",
    "  * $\\displaystyle\\frac{{s}_{{x}}}{\\sqrt{{{n}}}}$: standard error, or the standard deviation of the sampling distribution for sample sizes of size n\n",
    "* Conclusions\n",
    "  * I am confidence_level% accurate that the true population mean ($\\mu$) lies in between my confidence interval\n",
    "  * If many samples were taken of size n and confidence intervals were taken, confidence_level% of those intervals would contain the true population mean ($\\mu$)\n",
    "* `norm(mean: float, standard_deviation: float).interval(confidence_level: float) -> tuple(float, float)` gives you the confidence level given the\n",
    "* P-value: $\\displaystyle\\text{norm.cdf}{\\left(\\frac{{\\overline{{x}}-\\mu}}{{\\frac{{s}_{{x}}}{\\sqrt{{{n}}}}}}\\right)}$\n",
    "  * Remember to multiply p values by 2 when doing double sided tests\n",
    "* You use t tests when you don't know the standard deviation of the population\n",
    "\n",
    "## Linear Regression Review\n",
    "\n",
    "* $\\displaystyle{b}={r}\\frac{{s}_{{y}}}{{s}_{{x}}}$\n",
    "* $\\displaystyle{a}=\\overline{{y}}-{b}\\overline{{x}}$\n",
    "* $\\displaystyle\\text{RMSE}=\\text{SD}_{\\text{Errors}}=\\sqrt{{{1}-{r}^{2}}}\\cdot\\text{SD}_{{y}}$\n",
    "  * This is the calculation for root mean square error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, binom, bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes\n",
    "\n",
    "* Pandas library objects, they have rows and columns with the columns having headers/names\n",
    "* **Variable**: A column in the dataframe\n",
    "* **Observation**: Each row in the dataframe\n",
    "\n",
    "To create pandas dataframe from CSV file:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df: DataFrame = pd.read_csv(\"File path, can be either from disk or from url\")\n",
    "```\n",
    "\n",
    "**Pull select columsn from dataframe**: Rows are all still there you just pick only the columns that you need, useful for plotting and isolating columns/variables to focus on, usage: `df[[\"column1\", \"column2\", \"etc.\"]]`\n",
    "\n",
    "**Select rows from dataframe**: Like an SQL query you do `df[condition]` and the condition can be anything about the variables/columns in that dataframe, for instance `df[df[\"Subject\"] == \"Stat\"]` or `df[df.Subject == \"STAT\"]` for accessing all rows that have the subject column in that row being stat\n",
    "\n",
    "* Pandas cheat sheet has more methods for row selection and sampling\n",
    "* Can also combine more complex boolean queries with logic operators just like where clause in SQL\n",
    "* When you combine queries you must use bitwise operators `(&, |)` instead of standard python logic operators `and, or`, example query: `df[(df[\"Subject\"] == \"STAT\") & (df[\"COURSE_NUMBER\"] > 200)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Data in Pandas\n",
    "* A group in a dataframe is a collection of rows that all share the same *categorical* variable(s) (columns)\n",
    "* To group by a specific *categorical* variable you do `df.groupby(\"VARIABLE_NAME\")` or `df.groupby(by=\"VARIABLE_NAME\")`\n",
    "* `.describe()` on a group gives you one var stats for the quantitative variable rows aggregated together by variable\n",
    "* `.agg()`: For aggregating groups, returns same thing as describe except you pick which one var stats you want to display instead of doing the full report for each row, usage: `df.groupby(\"CategoricalVariable\").agg(\"mean\").reset_index()` to aggregate all quantitative variable rows\n",
    "    * use `reset_index()` after agg to get ordered list with indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Season</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OpponentRank</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">IlliniScore</th>\n",
       "      <th colspan=\"8\" halign=\"left\">OpponentScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opponent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Air Force</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1979.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>1979.25</td>\n",
       "      <td>1979.5</td>\n",
       "      <td>1979.75</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.25</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.25</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.75</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akron</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.500000</td>\n",
       "      <td>16.263456</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>2001.75</td>\n",
       "      <td>2007.5</td>\n",
       "      <td>2013.25</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>41.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1982.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1982.00</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1982.00</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Osteopath</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1902.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>1902.25</td>\n",
       "      <td>1902.5</td>\n",
       "      <td>1902.75</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32.50</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1993.500000</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1992.25</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1995.25</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.764823</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.75</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.25</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Illinois</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2013.333333</td>\n",
       "      <td>5.686241</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2016.50</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>8.082904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Kentucky</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015.500000</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2014.75</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>2016.25</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.50</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>19.091883</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.75</td>\n",
       "      <td>20.5</td>\n",
       "      <td>27.25</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Michigan</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1999.666667</td>\n",
       "      <td>26.112577</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>2005.00</td>\n",
       "      <td>2009.5</td>\n",
       "      <td>2011.75</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28.50</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>9.537645</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.50</td>\n",
       "      <td>21.5</td>\n",
       "      <td>26.00</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>87.0</td>\n",
       "      <td>1966.758621</td>\n",
       "      <td>34.164774</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>1944.00</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1994.50</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.00</td>\n",
       "      <td>51.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.540230</td>\n",
       "      <td>14.123874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.50</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Youngstown State</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Season                                                   \\\n",
       "                    count         mean        std     min      25%     50%   \n",
       "Opponent                                                                     \n",
       "Air Force             2.0  1979.500000   0.707107  1979.0  1979.25  1979.5   \n",
       "Akron                 2.0  2007.500000  16.263456  1996.0  2001.75  2007.5   \n",
       "Alabama               1.0  1982.000000        NaN  1982.0  1982.00  1982.0   \n",
       "American Osteopath    2.0  1902.500000   0.707107  1902.0  1902.25  1902.5   \n",
       "Arizona               4.0  1993.500000   2.645751  1990.0  1992.25  1994.0   \n",
       "...                   ...          ...        ...     ...      ...     ...   \n",
       "Western Illinois      3.0  2013.333333   5.686241  2007.0  2011.00  2015.0   \n",
       "Western Kentucky      2.0  2015.500000   2.121320  2014.0  2014.75  2015.5   \n",
       "Western Michigan      6.0  1999.666667  26.112577  1947.0  2005.00  2009.5   \n",
       "Wisconsin            87.0  1966.758621  34.164774  1895.0  1944.00  1969.0   \n",
       "Youngstown State      1.0  2014.000000        NaN  2014.0  2014.00  2014.0   \n",
       "\n",
       "                                    OpponentRank        ... IlliniScore        \\\n",
       "                        75%     max        count  mean  ...         75%   max   \n",
       "Opponent                                                ...                     \n",
       "Air Force           1979.75  1980.0          0.0   NaN  ...       25.25  27.0   \n",
       "Akron               2013.25  2019.0          0.0   NaN  ...       41.00  42.0   \n",
       "Alabama             1982.00  1982.0          0.0   NaN  ...       15.00  15.0   \n",
       "American Osteopath  1902.75  1903.0          0.0   NaN  ...       32.50  36.0   \n",
       "Arizona             1995.25  1996.0          0.0   NaN  ...       14.50  16.0   \n",
       "...                     ...     ...          ...   ...  ...         ...   ...   \n",
       "Western Illinois    2016.50  2018.0          0.0   NaN  ...       39.00  44.0   \n",
       "Western Kentucky    2016.25  2017.0          0.0   NaN  ...       36.50  42.0   \n",
       "Western Michigan    2011.75  2016.0          0.0   NaN  ...       28.50  60.0   \n",
       "Wisconsin           1994.50  2020.0          1.0  14.0  ...       24.00  51.0   \n",
       "Youngstown State    2014.00  2014.0          0.0   NaN  ...       28.00  28.0   \n",
       "\n",
       "                   OpponentScore                                           \\\n",
       "                           count       mean        std   min    25%   50%   \n",
       "Opponent                                                                    \n",
       "Air Force                    2.0  19.500000   0.707107  19.0  19.25  19.5   \n",
       "Akron                        2.0   5.000000   2.828427   3.0   4.00   5.0   \n",
       "Alabama                      1.0  21.000000        NaN  21.0  21.00  21.0   \n",
       "American Osteopath           2.0   0.000000   0.000000   0.0   0.00   0.0   \n",
       "Arizona                      4.0  23.000000  14.764823   7.0  13.75  22.0   \n",
       "...                          ...        ...        ...   ...    ...   ...   \n",
       "Western Illinois             3.0   4.666667   8.082904   0.0   0.00   0.0   \n",
       "Western Kentucky             2.0  20.500000  19.091883   7.0  13.75  20.5   \n",
       "Western Michigan             6.0  20.833333   9.537645   7.0  15.50  21.5   \n",
       "Wisconsin                   87.0  19.540230  14.123874   0.0   7.00  20.0   \n",
       "Youngstown State             1.0  17.000000        NaN  17.0  17.00  17.0   \n",
       "\n",
       "                                 \n",
       "                      75%   max  \n",
       "Opponent                         \n",
       "Air Force           19.75  20.0  \n",
       "Akron                6.00   7.0  \n",
       "Alabama             21.00  21.0  \n",
       "American Osteopath   0.00   0.0  \n",
       "Arizona             31.25  41.0  \n",
       "...                   ...   ...  \n",
       "Western Illinois     7.00  14.0  \n",
       "Western Kentucky    27.25  34.0  \n",
       "Western Michigan    26.00  34.0  \n",
       "Wisconsin           27.50  56.0  \n",
       "Youngstown State    17.00  17.0  \n",
       "\n",
       "[133 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output of describe on the football set\n",
    "df: pd.DataFrame = pd.read_csv(\"Datasets/football.csv\")\n",
    "group = df.groupby(\"Opponent\")\n",
    "group.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Data/Graphs\n",
    "\n",
    "Use `df.plot` as a base to start\n",
    "\n",
    "**Available functions in `df.plot`**:\n",
    "\n",
    "* `bar()` or `barh()`: bar graph (normal or horizontal) for categorical variables\n",
    "* `scatter(x: str, y: str)`: scatter plot (dot plot in 2 dimensions), x and y are names of variables\n",
    "* `hist()`: histogram\n",
    "* `box()`: box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"IlliniScore\"]].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Review\n",
    "\n",
    "* **Machine Learning**: Broad area of data science that involves any computer algorithm where data is used to help predict an accurate and reasonable outcome\n",
    "  * **Supervised Learning**: Learn to predict correct answer by training on data that has the right answer already, like image recognition where you know which images are what\n",
    "  * **Unsupervised Learning**: Learn on data where right answer is not provided, make your own conclusions and figure out along the way, like music recommendations\n",
    "    **Reinforcement Learning**: Trying different strategies and seeing what works and what doesn't work to \"learn\" what is best to do\n",
    "* **Classification**: Trying to predict a categorical variable or classify something into a group\n",
    "* **Prediction**: Trying to predict an exact quantitative value\n",
    "* `df.corr()`: Get correlation coefficient matrix for every single quantitative variable in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IlliniScore</th>\n",
       "      <th>OpponentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IlliniScore</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.128844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpponentScore</th>\n",
       "      <td>-0.128844</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               IlliniScore  OpponentScore\n",
       "IlliniScore       1.000000      -0.128844\n",
       "OpponentScore    -0.128844       1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"IlliniScore\",\"OpponentScore\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Models Review\n",
    "\n",
    "* **Linear Regression**: `from sklearn.linear_model import LinearRegression`\n",
    "  * `fit(features, targets)` takes in a dataframe of whatever features to use and the correct answers for the targets (the response or dependent variable) to train on\n",
    "* **K Means**: `from sklearn.cluster import KMeans`, you do `model: KMeans = KMeans(number_centroids: int)`\n",
    "  * Data needs to be numeric when it goes in, you fit and train the same way as wiht linear regression\n",
    "  * **Centroids**: Averages of datapoints\n",
    "  * It is an unsupervised machine learning algorithm kind of similar to KNN but KNN is supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_price</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.812206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.812206</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predicted_price     price\n",
       "predicted_price         1.000000  0.812206\n",
       "price                   0.812206  1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "df: pd.DataFrame = pd.read_csv(\"Datasets/diamonds.csv\")\n",
    "cutoff_index: int = int(len(df) * 0.75)\n",
    "# Split training and testing data\n",
    "training_data: pd.DataFrame = df.iloc[0:cutoff_index].drop([\"cut\", \"color\", \"clarity\"], axis=\"columns\")\n",
    "testing_data: pd.DataFrame = df.iloc[cutoff_index: len(df)].drop([\"cut\", \"color\", \"clarity\"], axis=\"columns\")\n",
    "# Train and then test the model on a cut down version of testing_data\n",
    "model: LinearRegression = LinearRegression().fit(training_data.drop([\"price\"], axis=\"columns\"), training_data[\"price\"])\n",
    "testing_data[\"predicted_price\"] = model.predict(testing_data.drop([\"price\"], axis=\"columns\"))\n",
    "testing_data[[\"predicted_price\", \"price\"]].corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat107",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
